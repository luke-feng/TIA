{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f978708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tia_util import remove_diag_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ced9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import torch \n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import os\n",
    "import pandas as pd\n",
    "from attack_models_sc4 import contrastive_normalization_np_withpower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b262abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ca6f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "metrics_root = f\"{cur_dir}\\\\saved_metrics\\\\\"\n",
    "topology_path = f\"{cur_dir}/topologies/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccd5ef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPOLOGY = [\"star\", \"ring\",\"ER_0.3\", \"ER_0.5\", \"ER_0.7\",'Abilene', 'brain', 'GÃ‰ANT', 'synth50', 'rf1755', 'rf3967', 'atlanta', 'brain',  'cost266', 'dfn-bwin', 'dfn-gwin', 'di-yuan', 'france',  'germany50', 'giul39', 'india35', 'janos-us', 'janos-us-ca', 'newyork', 'nobel-eu', 'nobel-germany', 'nobel-us', 'norway', 'pdh', 'pioro40', 'polska', 'sun', 'ta1', 'ta2', 'zib54']\n",
    "NUM_CLIENTS = [10, 20,30,12,22,50,79,87, 15, 161, 37, 11, 25, 35, 26, 39, 16, 28, 17, 14,  40,  27, 24, 65, 54]\n",
    "TOPOLOGY = [\"star\", \"ring\",\"ER_0.3\", \"ER_0.5\", \"ER_0.7\"]\n",
    "# NUM_CLIENTS = [10, 20,30]\n",
    "# DATASET = [\"Cifar10no\", \"Cifar10\", \"Mnist\",\"FMnist\", \"imagenet10\", \"pcam\", \"svhn\"]\n",
    "DATASET = [\"Cifar10\"]\n",
    "MODEL = [\"mlp\", \"mobile\",\"resnet\",\"pf\"]\n",
    "# MODEL = [\"mlp\", \"mobile\", \"resnet\"]\n",
    "IID = [1]\n",
    "MAX_EPOCHS = [3]\n",
    "ALPHA = 0.1\n",
    "SEED = [42]\n",
    "all_metrics_sc = os.listdir(metrics_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b501b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c403486",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "j:\\TIA\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDGEPRE Test F1: 1.0\n",
      "EDGEPRE Test F1: 0.9824561403508771\n",
      "EDGEPRE Test F1: 0.9846743295019157\n",
      "EDGEPRE Test F1: 1.0\n",
      "EDGEPRE Test F1: 1.0\n",
      "EDGEPRE Test F1: 1.0\n",
      "EDGEPRE Test F1: 0.9629629629629629\n",
      "EDGEPRE Test F1: 0.8070175438596491\n",
      "EDGEPRE Test F1: 0.8505747126436781\n",
      "EDGEPRE Test F1: 0.9259259259259259\n",
      "EDGEPRE Test F1: 0.6842105263157895\n",
      "EDGEPRE Test F1: 0.7241379310344828\n",
      "EDGEPRE Test F1: 0.9259259259259259\n",
      "EDGEPRE Test F1: 0.6929824561403509\n",
      "EDGEPRE Test F1: 0.6973180076628352\n"
     ]
    }
   ],
   "source": [
    "all_res = []\n",
    "for dataset in DATASET:\n",
    "        for model_name in MODEL:\n",
    "            # dataset and model setting\n",
    "            for topo in TOPOLOGY:\n",
    "               for iid in IID:\n",
    "                    for seed in SEED:\n",
    "                        for max_epoch in MAX_EPOCHS:\n",
    "                            for num in NUM_CLIENTS:\n",
    "                                ROUND =  num\n",
    "                                toponame_file = f\"{topology_path}/{num}_{topo}.pk\"\n",
    "                                if os.path.exists(toponame_file):  \n",
    "                                    with open(toponame_file, \"rb\") as f:\n",
    "                                        G = pk.load(f)\n",
    "                                        density = nx.density(G)\n",
    "                                        label = nx.adjacency_matrix(G).todense()\n",
    "                                else:\n",
    "                                    continue\n",
    "                                \n",
    "                                scenario_name = dataset + \"_\" + model_name + \"_\" + topo + \"_\" + str(iid) + \"_\" + str(ALPHA) + \"_\" + str(seed) + \"_\" + str(max_epoch) + \"_\" + str(num)\n",
    "                                if scenario_name in all_metrics_sc:\n",
    "                                    all_metrics = {}\n",
    "                                    # for approach in ['_cosine_metric', '_curvature_divergence', '_entropy_metric', '_euclidean_metric', '_jacobian_metric', '_loss_metric']:\n",
    "                                    try:\n",
    "                                        for approach in ['_cosine_metric', '_loss_metric']:                                                                          \n",
    "                                            metric_path = os.path.join(metrics_root,scenario_name, f'{approach}.csv')                                        \n",
    "                                            metrics = pd.read_csv(metric_path, index_col=0)\n",
    "                                            all_metrics[approach] = metrics\n",
    "                                    except:\n",
    "                                        continue\n",
    "                                            \n",
    "                                    y = remove_diag_reshape(label).flatten()\n",
    "                                    cosval = np.copy(all_metrics['_cosine_metric'])\n",
    "                                    cosval = contrastive_normalization_np_withpower(cosval, eta=3)\n",
    "                                    X_cos = remove_diag_reshape(cosval).flatten()\n",
    "                                    # X = X_cos.reshape((len(X_cos),1))\n",
    "\n",
    "                                    lossval = np.copy(all_metrics['_cosine_metric'])\n",
    "                                    lossval = contrastive_normalization_np_withpower(lossval, eta=3)\n",
    "                                    X_loss= remove_diag_reshape(lossval).flatten()\n",
    "                                    # # X_loss = X_loss.reshape((len(X_loss),1))\n",
    "\n",
    "                                    X = np.stack([X_cos, X_loss], axis=1)\n",
    "                                    X = X.reshape((len(X),2))\n",
    "                                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "                                    \n",
    "                                    # res = {}\n",
    "                                    # model = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "                                    # model.fit(X_train, y_train)\n",
    "                                    # y_pred = model.predict(X_test)\n",
    "                                    # f1 = f1_score(y_test, y_pred, average='micro')\n",
    "                                    # res['value'] = f1\n",
    "                                    # res['alg'] = \"LogisticRegression\"\n",
    "                                    # res['dataset'] = dataset\n",
    "                                    # res['topo'] = topo                                        \n",
    "                                    # res['iid'] = iid\n",
    "                                    # res['max_epoch'] = max_epoch\n",
    "                                    # res['num'] = num\n",
    "                                    # res['density'] = density\n",
    "                                    # res['approach'] = approach\n",
    "                                    # all_res.append(res)\n",
    "                                    \n",
    "                                    # res = {}\n",
    "                                    # model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "                                    # model.fit(X_train, y_train)\n",
    "                                    # y_pred = model.predict(X_test)\n",
    "                                    # f1 = f1_score(y_test, y_pred, average='micro')\n",
    "                                    # res['value'] = f1\n",
    "                                    # res['alg'] = \"RandomForestClassifier\"\n",
    "                                    # res['dataset'] = dataset\n",
    "                                    # res['topo'] = topo                                        \n",
    "                                    # res['iid'] = iid\n",
    "                                    # res['max_epoch'] = max_epoch\n",
    "                                    # res['num'] = num\n",
    "                                    # res['density'] = density\n",
    "                                    # res['approach'] = approach\n",
    "                                    # all_res.append(res)\n",
    "                                    \n",
    "                                    # res = {}\n",
    "                                    # model = SVC(class_weight='balanced', random_state=42)\n",
    "                                    # model.fit(X_train, y_train)\n",
    "                                    # y_pred = model.predict(X_test)\n",
    "                                    # f1 = f1_score(y_test, y_pred, average='micro')\n",
    "                                    # res = {}\n",
    "                                    # res['value'] = f1\n",
    "                                    # res['alg'] = \"SVC\"\n",
    "                                    # res['dataset'] = dataset\n",
    "                                    # res['topo'] = topo                                        \n",
    "                                    # res['iid'] = iid\n",
    "                                    # res['max_epoch'] = max_epoch\n",
    "                                    # res['num'] = num\n",
    "                                    # res['density'] = density\n",
    "                                    # res['approach'] = approach\n",
    "                                    # all_res.append(res)\n",
    "                                    \n",
    "                                    model = MLPClassifier(random_state=42, max_iter=500, solver='adam')\n",
    "                                    model.fit(X_train, y_train)\n",
    "                                    y_pred = model.predict(X_test)\n",
    "                                    f1 = f1_score(y_test, y_pred, average='micro')\n",
    "                                    print(\"EDGEPRE Test F1:\", f1)\n",
    "                                    res = {}\n",
    "                                    res['value'] = f1\n",
    "                                    res['alg'] = \"EDGEPRE\"\n",
    "                                    res['dataset'] = dataset\n",
    "                                    res['topo'] = topo                                        \n",
    "                                    res['iid'] = iid\n",
    "                                    res['max_epoch'] = max_epoch\n",
    "                                    res['num'] = num\n",
    "                                    res['density'] = density\n",
    "                                    res['approach'] = approach\n",
    "                                    all_res.append(res)                                                                   \n",
    "                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f6f10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(all_res)\n",
    "res_df.to_csv('sc1_cfaug.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
