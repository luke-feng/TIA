{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import networkx as nx\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_object(num, name):\n",
    "    if name == \"fully\":\n",
    "        G = nx.complete_graph(num)\n",
    "    elif name == \"star\":\n",
    "        G = nx.star_graph(num - 1)\n",
    "    elif name == \"ring\":\n",
    "        G = nx.cycle_graph(num)\n",
    "    elif name.startswith(\"ER_\"):\n",
    "        try:\n",
    "            # Extract probability and seed from the graph_info\n",
    "            parts = name.split(\"_\")\n",
    "            prob = float(parts[1])\n",
    "            G = nx.erdos_renyi_graph(num, prob, seed=45)\n",
    "        except (IndexError, ValueError):\n",
    "            raise ValueError(\"Invalid format for ER graph type. Expected 'ER_prob'\")\n",
    "    else:\n",
    "        raise ValueError(\"Not supported topology.\")        \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in [10,20,30]:\n",
    "    for name in [\"fully\", \"star\", \"ring\", \"ER_0.3\", \"ER_0.7\", \"ER_0.5\"]:\n",
    "        G = create_graph_object(num, name)\n",
    "        with open(f'{num}_{name}.pk','wb') as f:\n",
    "            pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abilene_edges.csv 12\n",
      "GÉANT_edges.csv 22\n",
      "synth50_edges.csv 50\n",
      "rf1755_edges.csv 87\n",
      "rf3967_edges.csv 79\n"
     ]
    }
   ],
   "source": [
    "for file_name in ['Abilene_edges.csv', 'GÉANT_edges.csv', 'synth50_edges.csv', 'rf1755_edges.csv', 'rf3967_edges.csv']:\n",
    "    edges_df = pandas.read_csv(file_name)\n",
    "    parts = file_name.split(\"_\")\n",
    "    topo = parts[0]\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in edges_df.iterrows():\n",
    "        G.add_edge(row['src'], row['dst'])\n",
    "    adj_matrix = nx.adjacency_matrix(G).todense()\n",
    "    print(file_name, len(adj_matrix))\n",
    "    with open(f'{len(adj_matrix)}_{topo}.pk','wb') as f:\n",
    "        pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import xml.etree.ElementTree as ET\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/abilene.xml\n",
      "12\n",
      "15\n",
      "abilene 12\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/atlanta.xml\n",
      "15\n",
      "22\n",
      "atlanta 15\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/brain.xml\n",
      "161\n",
      "332\n",
      "brain 161\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/cost266.xml\n",
      "37\n",
      "57\n",
      "cost266 37\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/dfn-bwin.xml\n",
      "10\n",
      "45\n",
      "dfn-bwin 10\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/dfn-gwin.xml\n",
      "11\n",
      "47\n",
      "dfn-gwin 11\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/di-yuan.xml\n",
      "11\n",
      "42\n",
      "di-yuan 11\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/france.xml\n",
      "25\n",
      "45\n",
      "france 25\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/geant.xml\n",
      "22\n",
      "36\n",
      "geant 22\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/germany50.xml\n",
      "50\n",
      "88\n",
      "germany50 50\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/giul39.xml\n",
      "39\n",
      "172\n",
      "giul39 39\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/india35.xml\n",
      "35\n",
      "80\n",
      "india35 35\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/janos-us.xml\n",
      "26\n",
      "84\n",
      "janos-us 26\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/janos-us-ca.xml\n",
      "39\n",
      "122\n",
      "janos-us-ca 39\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/newyork.xml\n",
      "16\n",
      "49\n",
      "newyork 16\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/nobel-eu.xml\n",
      "28\n",
      "41\n",
      "nobel-eu 28\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/nobel-germany.xml\n",
      "17\n",
      "26\n",
      "nobel-germany 17\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/nobel-us.xml\n",
      "14\n",
      "21\n",
      "nobel-us 14\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/norway.xml\n",
      "27\n",
      "51\n",
      "norway 27\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/pdh.xml\n",
      "11\n",
      "34\n",
      "pdh 11\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/pioro40.xml\n",
      "40\n",
      "89\n",
      "pioro40 40\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/polska.xml\n",
      "12\n",
      "18\n",
      "polska 12\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/sun.xml\n",
      "27\n",
      "102\n",
      "sun 27\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/ta1.xml\n",
      "24\n",
      "55\n",
      "ta1 24\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/ta2.xml\n",
      "65\n",
      "108\n",
      "ta2 65\n",
      "Fetching https://sndlib.put.poznan.pl/download/sndlib-networks-xml/zib54.xml\n",
      "54\n",
      "81\n",
      "zib54 54\n"
     ]
    }
   ],
   "source": [
    "NETWORK_LIST = [\n",
    "    \"abilene\", \"atlanta\", \"brain\", \"cost266\", \"dfn-bwin\", \"dfn-gwin\", \"di-yuan\",\n",
    "    \"france\", \"geant\", \"germany50\", \"giul39\", \"india35\", \"janos-us\", \"janos-us-ca\",\n",
    "    \"newyork\", \"nobel-eu\", \"nobel-germany\", \"nobel-us\", \"norway\", \"pdh\", \"pioro40\",\n",
    "    \"polska\", \"sun\", \"ta1\", \"ta2\", \"zib54\"\n",
    "]\n",
    "\n",
    "BASE_URL = \"https://sndlib.put.poznan.pl/download/sndlib-networks-xml/\"\n",
    "\n",
    "def find_tag_ignore_namespace(root, tag):\n",
    "    return next((elem for elem in root.iter() if elem.tag.endswith(tag)), None)\n",
    "\n",
    "def find_all_tags_ignore_namespace(root, tag):\n",
    "    return [elem for elem in root.iter() if elem.tag.endswith(tag)]\n",
    "\n",
    "def safe_find_text(elem, tag):\n",
    "    for child in elem:\n",
    "        if child.tag.endswith(tag):\n",
    "            return child.text\n",
    "    return None\n",
    "\n",
    "def parse_and_save_adj_matrix(name, save_dir=\"adj_matrices\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    url = f\"{BASE_URL}{name}.xml\"\n",
    "    print(f\"Fetching {url}\")\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        root = ET.fromstring(r.content)\n",
    "\n",
    "        G = nx.DiGraph(name=name)\n",
    "\n",
    "        node_elements = find_all_tags_ignore_namespace(root, 'node')\n",
    "        link_elements = find_all_tags_ignore_namespace(root, 'link')\n",
    "\n",
    "        if not node_elements or not link_elements:\n",
    "            raise ValueError(\"Missing <node> or <link> in XML\")\n",
    "\n",
    "        # Map node IDs to 0-based indices\n",
    "        node_id_map = {}\n",
    "        print(len(node_elements))\n",
    "        print(len(link_elements))\n",
    "        for idx, node in enumerate(node_elements):\n",
    "            node_id_map[node.attrib['id']] = idx\n",
    "            G.add_node(idx)\n",
    "\n",
    "        # Add edges using 0-based node indices\n",
    "        for link in link_elements:\n",
    "            src = safe_find_text(link, 'source')\n",
    "            dst = safe_find_text(link, 'target')\n",
    "            if src is not None and dst is not None:\n",
    "                G.add_edge(node_id_map[src], node_id_map[dst])\n",
    "        # Save adjacency matrix\n",
    "        adj_matrix = nx.adjacency_matrix(G).todense()\n",
    "        \n",
    "        print(name, len(adj_matrix))\n",
    "        with open(f'{len(adj_matrix)}_{name}.pk','wb') as f:\n",
    "            pickle.dump(G, f)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {name}: {e}\")\n",
    "\n",
    "def process_all_networks():\n",
    "    for name in NETWORK_LIST:\n",
    "        parse_and_save_adj_matrix(name)\n",
    "        time.sleep(0.5)  # polite delay\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_networks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
